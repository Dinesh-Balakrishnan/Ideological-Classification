{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XERw45n_RfPL",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network Classification: Word 2 Vector\n",
        "\n",
        "----\n",
        "\n",
        "## Dataset Preprocessing\n",
        "\n",
        "### Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lw6BV9TUW8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "[lib, con, neutral] = pickle.load(open('ibcData.pkl', 'rb'))\n",
        "\n",
        "lib = [sentence.get_words() for sentence in lib]\n",
        "con = [sentence.get_words() for sentence in con]\n",
        "\n",
        "reviews = lib + con\n",
        "positions = [0]*len(lib) + [1]*len(con)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQikZPrbUky-",
        "colab_type": "text"
      },
      "source": [
        "### Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdeSf-fmUbGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ab811b79-1cc7-49f1-c3c5-9cda172a4cf9"
      },
      "source": [
        "# Default Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Word Tokenizing Imports\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Model Evaluation Imports\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "# 'stopwords' Library Import\n",
        "from re import sub\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88yDIiYVU2eO",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjqm6CmU1QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing Stopwords list\n",
        "ignored_words = set(stopwords.words('english'))\n",
        "ignored_words.remove('not')\n",
        "\n",
        "# Initializing the tokenizing classes.\n",
        "stemmer = PorterStemmer()\n",
        "tokenizer = Tokenizer(oov_token = '<OOV>')\n",
        "corpus = []\n",
        "\n",
        "for review in reviews:\n",
        "    # Standardizing character range to a-z.\n",
        "    review = review.lower()\n",
        "    review = sub('[^a-z]', ' ', review)\n",
        "\n",
        "    # Removing less valuable words: the 'stopwords'\n",
        "    review = review.split()\n",
        "    review = [stemmer.stem(word) for word in review if not word in ignored_words]\n",
        "    review = ' '.join(review)\n",
        "    \n",
        "    corpus.append(review)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "X = tokenizer.texts_to_sequences(corpus)\n",
        "X = pad_sequences(X, padding='post')\n",
        "y = positions"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoUhjY0SWTtv",
        "colab_type": "text"
      },
      "source": [
        "### Creating Training & Testing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzHcQVyeWK4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_jt4J1Nr4s0",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "\n",
        "## Creating the Model\n",
        "\n",
        "### Basic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQJA4aXEsbep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "4fa6a2d2-d4ef-4a10-877b-01ec53f1e50b"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding((len(tokenizer.word_index) + 1), 16),\n",
        "      tf.keras.layers.GlobalMaxPooling1D(),\n",
        "      tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "  \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          132432    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 132,721\n",
            "Trainable params: 132,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5352\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5450\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6653\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7913\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8415\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8917\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9283\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9545\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9747\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af31f7550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_iRALtpCvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "96cff6bd-3a02-4020-dadd-371200ed8184"
      },
      "source": [
        "predictions = [round(value[0]) for value in model.predict(X_test)]\n",
        "print(accuracy_score(predictions, y_test))\n",
        "print(f1_score(predictions, y_test))\n",
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6207513416815742\n",
            "0.5564853556485356\n",
            "[[214 103]\n",
            " [109 133]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE6-vCnbwyuz",
        "colab_type": "text"
      },
      "source": [
        "### Increasing Embedding Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VkVj2ukWwtsU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "22be0b0b-dfb0-4044-ca54-96dd0df3a923"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding((len(tokenizer.word_index) + 1), 32),\n",
        "      tf.keras.layers.GlobalMaxPooling1D(),\n",
        "      tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "  \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          264864    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 265,953\n",
            "Trainable params: 265,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5384\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6069\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7584\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8453\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.9116\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.9580\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9785\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9880\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af34db7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BplIJ_gwwtsW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fac56388-31a1-40db-ce27-151fe27f5fd2"
      },
      "source": [
        "predictions = [round(value[0]) for value in model.predict(X_test)]\n",
        "print(accuracy_score(predictions, y_test))\n",
        "print(f1_score(predictions, y_test))\n",
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6046511627906976\n",
            "0.5099778270509978\n",
            "[[223 121]\n",
            " [100 115]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEvJBbM8yCyF",
        "colab_type": "text"
      },
      "source": [
        "### Further Increasing Embedding Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPxVeY8DyrqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "134a1b4c-3bba-48ed-cd5c-7429e5636ad6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding((len(tokenizer.word_index) + 1), 64),\n",
        "      tf.keras.layers.GlobalMaxPooling1D(),\n",
        "      tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "  \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 64)          529728    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 533,953\n",
            "Trainable params: 533,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.6887 - accuracy: 0.5380\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.6493 - accuracy: 0.6514\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.4898 - accuracy: 0.8169\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.2827 - accuracy: 0.9138\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.1358 - accuracy: 0.9687\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0656 - accuracy: 0.9864\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0372 - accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0274 - accuracy: 0.9924\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9931\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af369dd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2_tP9lDqyrqN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e0e3dfca-f15f-4a83-a833-62af9ac54e2f"
      },
      "source": [
        "predictions = [round(value[0]) for value in model.predict(X_test)]\n",
        "print(accuracy_score(predictions, y_test))\n",
        "print(f1_score(predictions, y_test))\n",
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6225402504472272\n",
            "0.5667351129363449\n",
            "[[210  98]\n",
            " [113 138]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZHEi-G9y5yG"
      },
      "source": [
        "### Increasing Dense Layer Count (Using 64 Dimension Embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vo22lKwsy5yH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "85438982-c476-42ec-9f67-56c530ab74be"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding((len(tokenizer.word_index) + 1), 64),\n",
        "      tf.keras.layers.GlobalMaxPooling1D(),\n",
        "      tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "  \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 64)          529728    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 536,001\n",
            "Trainable params: 536,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.6892 - accuracy: 0.5327\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.6506 - accuracy: 0.6321\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.4249 - accuracy: 0.8295\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.1796 - accuracy: 0.9422\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0637 - accuracy: 0.9845\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0327 - accuracy: 0.9921\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0276 - accuracy: 0.9927\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0239 - accuracy: 0.9927\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0212 - accuracy: 0.9940\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0202 - accuracy: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af3807dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_G7bcysEy5yJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8640a036-315d-4136-a021-093e44d28b66"
      },
      "source": [
        "predictions = [round(value[0]) for value in model.predict(X_test)]\n",
        "print(accuracy_score(predictions, y_test))\n",
        "print(f1_score(predictions, y_test))\n",
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.59391771019678\n",
            "0.5725047080979284\n",
            "[[180  84]\n",
            " [143 152]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g7iMNJJ_zc61"
      },
      "source": [
        "### Reducing Dense Layer Nodes (Using 64 Dimension Embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M1qPZKWBzc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "3bf8f6ee-d3c9-4e2a-9724-4ba3b0af7459"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding((len(tokenizer.word_index) + 1), 64),\n",
        "      tf.keras.layers.GlobalMaxPooling1D(),\n",
        "      tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(2, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "  \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 64)          529728    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 130       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 534,021\n",
            "Trainable params: 534,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.6893 - accuracy: 0.5374\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.6675 - accuracy: 0.5589\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.5481 - accuracy: 0.7540\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.3270 - accuracy: 0.8930\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9583\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0677 - accuracy: 0.9852\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0347 - accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0249 - accuracy: 0.9927\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0216 - accuracy: 0.9927\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af399bc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ng3Vl-pPzc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5568feae-49be-489e-a4c0-653effbbd2f0"
      },
      "source": [
        "predictions = [round(value[0]) for value in model.predict(X_test)]\n",
        "print(accuracy_score(predictions, y_test))\n",
        "print(f1_score(predictions, y_test))\n",
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6135957066189625\n",
            "0.5423728813559322\n",
            "[[215 108]\n",
            " [108 128]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg6bgsUX9JcY",
        "colab_type": "text"
      },
      "source": [
        "### Reducing Dense Layer Nodes (Using 16 Dimension Embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wEDT0Tzs9P0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "a3591f0f-1c77-48ed-e1c4-fb92179ddbe9"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding((len(tokenizer.word_index) + 1), 16),\n",
        "      tf.keras.layers.GlobalMaxPooling1D(),\n",
        "      tf.keras.layers.Dense(8, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "  \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 16)          132432    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 132,577\n",
            "Trainable params: 132,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5343\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5699\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6704\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7831\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8371\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8775\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.9179\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9432\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9621\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af3943e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TY03G9lk9P0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "51015a30-4b9f-4db3-8685-10357f7591f7"
      },
      "source": [
        "predictions = [round(value[0]) for value in model.predict(X_test)]\n",
        "print(accuracy_score(predictions, y_test))\n",
        "print(f1_score(predictions, y_test))\n",
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6529516994633273\n",
            "0.5800865800865802\n",
            "[[231 102]\n",
            " [ 92 134]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
